// src/pages/FeynmanRecordPage.jsx
import { useReactMediaRecorder } from 'react-media-recorder';
import { useParams } from 'react-router-dom';
import { useState, useEffect } from 'react';
import apiClient from '../api/axios';

function FeynmanRecordPage() {
    const { id } = useParams(); // çŸ¥è¯†ç‚¹ID
    const [kpTitle, setKpTitle] = useState('');
    const [transcribedText, setTranscribedText] = useState('');
    const [isUploading, setIsUploading] = useState(false);
    const [aiFeedback, setAiFeedback] = useState(null);
    const [isEvaluating, setIsEvaluating] = useState(false);

    useEffect(() => {
        // è·å–çŸ¥è¯†ç‚¹æ ‡é¢˜ç”¨äºæ˜¾ç¤º
        const fetchKpTitle = async () => {
            const response = await apiClient.get(`/knowledge-points/${id}`);
            if (response.data.code !== 0) {
                console.error('è·å–çŸ¥è¯†ç‚¹å¤±è´¥');
                return;
            }
            setKpTitle(response.data.title);
        };
        fetchKpTitle();
    }, [id]);

    // æ–°å¢ä¸€ä¸ªå‡½æ•°æ¥å¤„ç†AIè¯„ä»·
    const getAiEvaluation = async (transcribed) => {
        setIsEvaluating(true);
        setAiFeedback(null);
        
        try {
            // è·å–åŸå§‹çŸ¥è¯†ç‚¹å†…å®¹
            const kpResponse = await apiClient.get(`/knowledge-points/${id}`);
            if (kpResponse.data.code != 0) {
                throw new Error(kpResponse.data.msg);
            } 
            const originalContent = kpResponse.data.data.kp.content;
            const feedbackResponse = await apiClient.post('/audio/evaluate', {
                originalContent: originalContent,
                transcribedText: transcribed
            });

            setAiFeedback(feedbackResponse.data);

        } catch (error) {
            console.error('è·å–AIè¯„ä»·å¤±è´¥', error);
        } finally {
            setIsEvaluating(false);
        }
    };

    const uploadAudio = async (blobUrl) => {
        setIsUploading(true);
        setTranscribedText('');
        try {
            const audioBlob = await fetch(blobUrl).then(r => r.blob());
            const audioFile = new File([audioBlob], `feynman-record-${id}.wav`, { type: 'audio/wav' });

            const formData = new FormData();
            formData.append('audio', audioFile); // 'audio'è¦å’Œåç«¯multerçš„å­—æ®µåä¸€è‡´
            formData.append('knowledgePointId', id); // é¡ºä¾¿æŠŠçŸ¥è¯†ç‚¹IDä¹Ÿä¼ è¿‡å»

            const response = await apiClient.post('/audio/transcribe', formData, {
                headers: {
                    'Content-Type': 'multipart/form-data',
                },
            });
            if (response.data.code !== 0) {
                throw new Error('è½¬å½•å¤±è´¥: ' + response.data.msg);
            }
            setTranscribedText(response.data.result);
            // å¦‚æœè½¬å½•æˆåŠŸä¸”æœ‰ç»“æœï¼Œè§¦å‘AIè¯„ä»·
            if (response.data.result) {
                getAiEvaluation(response.data.result); 
                }
        } catch (error) {
            console.error('ä¸Šä¼ æˆ–è½¬å½•å¤±è´¥', error);
            setTranscribedText('è½¬å½•å¤±è´¥ï¼Œè¯·é‡è¯•ã€‚ ${error.message || error.toString()}');
        } finally {
            setIsUploading(false);
        }
    };
    
    // ä½¿ç”¨Hookï¼Œåœ¨åœæ­¢æ—¶è‡ªåŠ¨ä¸Šä¼ 
    const { status: recStatus, startRecording: recStart, stopRecording: recStop, mediaBlobUrl: recUrl } = useReactMediaRecorder({ 
      audio: true,
      onStart: () => {
        console.log("å¼€å§‹ ")
      },
      onError: (error) => {
        console.log("==========")    
        console.error('å½•åˆ¶é”™è¯¯:', error);
        console.log("==========")
        },
      onStop: (blobUrl) => {
        console.log("åœ")
        uploadAudio(blobUrl);
      }
    });
    return (
        <div>
            <h1>å¤è¿°çŸ¥è¯†ç‚¹: {kpTitle}</h1>
            <p>å½•éŸ³çŠ¶æ€: {recStatus}</p>
            
            <button onClick={recStart} disabled={recStatus === 'recording'}>å¼€å§‹å½•éŸ³</button>
            <button onClick={recStop} disabled={recStatus !== 'recording'}>åœæ­¢å½•éŸ³</button>

            {recUrl && <audio src={recUrl} controls />}

            <hr />

            <h2>AI è½¬å½•ç»“æœ:</h2>
            {isUploading && <p>æ­£åœ¨ä¸Šä¼ å¹¶è½¬å½•ï¼Œè¯·ç¨å€™...</p>}
            <div style={{ border: '1px solid #ccc', padding: '1rem', minHeight: '100px' }}>
                {transcribedText}
            </div>
            
            {/* ... åœ¨è½¬å½•ç»“æœ div ä¸‹æ–¹*/}
            <hr />
            <h2>AI æ•™ç»ƒåé¦ˆ:</h2>
            {isEvaluating && <p>AIæ•™ç»ƒæ­£åœ¨æ‰¹é˜…æ‚¨çš„ç­”å·...</p>}
            {aiFeedback && (
                <div className="ai-feedback" style={{ display: 'flex', gap: '2rem' }}>
                    <div style={{ flex: 1 }}>
                        <h3>AI æ¶¦è‰²åçš„æ–‡æœ¬</h3>
                        <p style={{ background: '#eef', padding: '1rem' }}>{aiFeedback.polishedText}</p>
                        
                        <h3>ç»¼åˆè¯„ä»·</h3>
                        <p>{aiFeedback.evaluation}</p>

                        <h3>ä¼˜ç‚¹ ğŸ‘</h3>
                        <ul>
                            {aiFeedback.strengths.map((item, index) => <li key={index}>{item}</li>)}
                        </ul>

                        <h3>å¾…æ”¹è¿› ğŸ‘‡</h3>
                        <ul>
                            {aiFeedback.weaknesses.map((item, index) => <li key={index}>{item}</li>)}
                        </ul>
                    </div>
                    <div style={{ flex: '0 0 150px', textAlign: 'center' }}>
                        <h3>ç»¼åˆå¾—åˆ†</h3>
                        <div style={{ fontSize: '3rem', fontWeight: 'bold', color: aiFeedback.score > 80 ? 'green' : 'orange' }}>
                            {aiFeedback.score}
                        </div>
                    </div>
                </div>
            )}
        </div>
    );
}

export default FeynmanRecordPage;
